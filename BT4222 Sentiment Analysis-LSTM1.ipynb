{"cells":[{"cell_type":"markdown","metadata":{"id":"5mcfMWlnjpoP"},"source":["# Note:\n","- This notebook file may contain methods or algorithms that are NOT covered by the teaching content of BT4222 and hence will not be assessed in your midterm exam.\n","- It serves to increase your exposure in depth and breath to the practical methods in addressing the specific project topic. We believe it will be helpful for your current project and also your future internship endeavors."]},{"cell_type":"markdown","metadata":{"id":"5VGWtN_Vr9Tn"},"source":["# LSTM for sentiment analysis\n","\n","This notebook provides an example of applying LSTM to imdb dataset based on pytorch. We adopted this [tutorial](https://medium.com/@khang.pham.exxact/hugging-face-text-classification-tutorial-using-pytorch-cd3d6bc33292) for this part. The dataset is only a subset of the original IMDB dataset for the convenience of reproducing with limited computing resource, so the accuracy would be lower.\n","\n","## Agenda\n","\n","1. Preparation and Data Loading\n","2. Tokenization and Padding\n","3. Batching and loading as tensor\n","4. Model structure\n","5. Training and evaluation\n","\n","\n","## Part 1: Preparation and data loading\n","We are going to Import the Necessary Libraries and Check if CUDA is Available for preparation stage.\n","\n","During this tutorial, most of the libraries used here will hopefully become more clear, but to begin we' ll explain some of the main libraries that were just imported:\n","\n","`NumPy`: freely create arrays and matrices. It also contains multiple linear algebra functions.\n","\n","`sklearn`: import and utilize the train_test_split function. This function allows us to split our data into both a training and testing data set. You can choose the ratio of the split, among other parameters, but more on that later.\n"]},{"cell_type":"markdown","metadata":{"id":"HEDuo36AjozJ"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_cTQzom0XCd"},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import nltk\n","from nltk.corpus import stopwords\n","from collections import Counter\n","import string\n","import re\n","import seaborn as sns\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"4Nbvfe4rBSQF"},"source":["Then, we check if a GPU is available to run or code on. If no GPU is provided then the code will process on a normal CPU."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1691856539893,"user":{"displayName":"Kevin Tang","userId":"05036585668706905920"},"user_tz":-480},"id":"8G92AFkL0iA2","outputId":"3f96cf16-2ffa-4139-e23a-867c9dec8903"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU is available\n"]}],"source":["# Check cuda status\n","is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"]},{"cell_type":"markdown","metadata":{"id":"oav7kYgctbQq"},"source":["### Data loading:\n","- Load the whole dataset in csv format\n","- Split it into training and testing data. Doing this on earlier stage allows to avoid data lekage.\n","- In `train_test_split` function, you can passed extra parameters like `test_size`: by passing a value of 0.2 we are instructing the train_test_split function to split our data set into 80% training and 20% testing sets."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2726,"status":"ok","timestamp":1691856542615,"user":{"displayName":"Kevin Tang","userId":"05036585668706905920"},"user_tz":-480},"id":"5Foj3xlk0nTl","outputId":"b978660c-45ce-4016-b5cf-16c0dfca15c8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1TPneTNMGP0tHQ94QxANmrkBtItgKG1Px\n","To: /content/Test.csv\n","100%|██████████| 6.61M/6.61M [00:00<00:00, 183MB/s]"]},{"name":"stdout","output_type":"stream","text":["shape of train data is (4000,)\n","shape of test data is (1000,)\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from google.colab import drive\n","\n","import gdown\n","\n","file_id = '1TPneTNMGP0tHQ94QxANmrkBtItgKG1Px'\n","url = f'https://drive.google.com/uc?id={file_id}'\n","output = 'Test.csv'\n","gdown.download(url, output, quiet=False)\n","\n","\n","base_csv = 'Test.csv'\n","df = pd.read_csv(base_csv)\n","\n","X,y = df['text'].values,df['label'].values\n","# drop a bunch of unrelated columns which are unnecessary for our model to work and are only slowing it down.\n","x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y, test_size=0.2)\n","print(f'shape of train data is {x_train.shape}')\n","print(f'shape of test data is {x_test.shape}')"]},{"cell_type":"markdown","metadata":{"id":"bx6BU2vPt40_"},"source":["## Part 2: Tokenization and Padding\n","**Tokenization**\n","\n","In this step we preprocess the string, remove stopwords and tokenize.\n","\n","Tokenization is the process of breaking down a piece of text into smaller units called tokens. These tokens can be words, subwords, or even characters, depending on the specific tokenization approach used. Tokenization is an essential step in natural language processing tasks as it helps to structure and analyze text data.\n","\n","The main concept behind tokenization is that by analyzing the different words present in a given text, we can interpret the meaning of such a text. We can also run statistical tools and methods to find hidden insights and patterns in the data.\n","\n","*In our tutorial of machine learning methods, we directly use a tokenizer in a well-developed library. Here, we provide an example of implementing a simple tokenizer from scratch.*\n","\n","**Several reasons for choosing 1000(or another value) most common words in the vocabulary:**\n"," - Reduction of Dimensionality and Complexity: Natural language contains a vast number of words, but not all words are equally important for a given task.\n","\n"," - Frequency and Information Content: Common words often have higher frequencies in the corpus. Consequently, they carry more information. For most NLP tasks, the semantics and contextual relationships of these common words are easier for models to capture, leading to improved performance.\n","\n"," - Data Sparsity: In a large vocabulary, many words might appear very infrequently, or even just once.\n","\n","- Reducing Noise Impact: Large-scale corpora can contain errors, misspellings, low-frequency words, or irrelevant terms. Selecting common words helps mitigate the impact of such noise on the model.\n","\n","The choice of vocabulary size should be adjusted based on the specifics of the task and dataset. A small vocabulary might limit a model's capabilities, while a large vocabulary might increase computational costs."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7444,"status":"ok","timestamp":1691856550051,"user":{"displayName":"Kevin Tang","userId":"05036585668706905920"},"user_tz":-480},"id":"1sN9FeSO1AQ_","outputId":"060d66e7-c1c3-4f07-bfb1-7b5b0a168be6"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["def preprocess_string(s):\n","    # Remove all non-word characters (everything except numbers and letters)\n","    s = re.sub(r\"[^\\w\\s]\", '', s)\n","    # Replace all runs of whitespaces with no space\n","    s = re.sub(r\"\\s+\", '', s)\n","    # replace digits with no space\n","    s = re.sub(r\"\\d\", '', s)\n","\n","    return s\n","\n","def tockenize(x_train,y_train,x_val,y_val):\n","    word_list = []\n","\n","    stop_words = set(stopwords.words('english'))\n","    for sent in x_train:\n","        # print(type(sent)) 'str'\n","        for word in sent.lower().split():\n","            word = preprocess_string(word)\n","            if word not in stop_words and word != '':\n","                word_list.append(word)\n","\n","    corpus = Counter(word_list)\n","    # sorting on the basis of 1000 most common words.\n","    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n","    # creating a dict\n","    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n","\n","    # tockenize\n","    final_list_train,final_list_test = [],[]\n","    for sent in x_train:\n","            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n","                                     if preprocess_string(word) in onehot_dict.keys()])\n","    for sent in x_val:\n","            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n","                                    if preprocess_string(word) in onehot_dict.keys()])\n","\n","    return np.array(final_list_train, dtype=object), np.array(final_list_test, dtype=object), onehot_dict\n","\n","nltk.download('stopwords')\n","x_train,x_test,vocab = tockenize(x_train,y_train,x_test,y_test)"]},{"cell_type":"markdown","metadata":{"id":"CXDKHGW3vf-M"},"source":["Now with every word tokenized, we can get the length of the vocabulary."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1691856550053,"user":{"displayName":"Kevin Tang","userId":"05036585668706905920"},"user_tz":-480},"id":"usziUFnB1H30","outputId":"3240c047-c662-4684-fc60-6e24b405963b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of vocabulary is 1000\n"]}],"source":["print(f'Length of vocabulary is {len(vocab)}')"]},{"cell_type":"markdown","metadata":{"id":"mnzi7NuYwvmQ"},"source":["We can analyze and visualize the length of preprocessed text."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":583},"executionInfo":{"elapsed":1134,"status":"ok","timestamp":1691856551177,"user":{"displayName":"Kevin Tang","userId":"05036585668706905920"},"user_tz":-480},"id":"-OIi1jjf1f3u","outputId":"d7927bfa-ff4d-4b23-d6b2-09ee210e263e"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["count    4000.000000\n","mean       68.986000\n","std        48.437412\n","min         6.000000\n","25%        39.000000\n","50%        54.000000\n","75%        83.000000\n","max       325.000000\n","dtype: float64"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["rev_len = [len(i) for i in x_train]\n","pd.Series(rev_len).hist()\n","plt.show()\n","pd.Series(rev_len).describe()"]},{"cell_type":"markdown","metadata":{"id":"qtmTu8oIw3Ko"},"source":["\n"," **Padding**\n","\n"," To ensure uniform sequence length for batch processing, we pad the text.\n","\n","Text data often varies in sentence or document length, but language models typically require fixed-length input sequences consisting of N tokens. Padding is used to address this issue by adding special padding tokens at the end of shorter sequences, making them all the same length. This allows multiple sequences to be placed in a batch and efficiently processed in parallel since they have the same length. During model processing, it learns to ignore padding tokens and focus only on the meaningful input tokens, thus not being affected by the padding. In summary, padding text sequences aims to achieve consistent sequence length for batch processing without impacting the model's ability to learn from actual information.\n","\n","We perform padding on the X values in the training and testing data set. Since most reviews have a length of below 500, we will only consider sentences below the 500 range."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYUo1K7y1jhc"},"outputs":[],"source":["def padding_(sentences, seq_len):\n","    features = np.zeros((len(sentences), seq_len),dtype=int)\n","    for ii, review in enumerate(sentences):\n","        if len(review) != 0:\n","            features[ii, -len(review):] = np.array(review)[:seq_len]\n","    return features\n","\n","#we have very less number of reviews with length > 500.\n","#So we will consideronly those below it.\n","x_train_pad = padding_(x_train,500)\n","x_test_pad = padding_(x_test,500)"]},{"cell_type":"markdown","metadata":{"id":"wIMYw8IWzV_M"},"source":["## Part 3: Batching and loading as tensor\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YE--C_um1nWM"},"outputs":[],"source":["# create Tensor datasets\n","train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n","valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n","\n","# dataloaders\n","batch_size = 50\n","\n","# make sure to SHUFFLE your data\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1691856551179,"user":{"displayName":"Kevin Tang","userId":"05036585668706905920"},"user_tz":-480},"id":"o0JiCY631pzc","outputId":"5a815822-f2cb-4b8b-e113-afa0b66a57e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample input size:  torch.Size([50, 500])\n","Sample input: \n"," tensor([[  0,   0,   0,  ..., 447, 102,  11],\n","        [  0,   0,   0,  ..., 554, 286, 244],\n","        [  0,   0,   0,  ..., 353, 410, 123],\n","        ...,\n","        [  0,   0,   0,  ...,   8, 221, 175],\n","        [  0,   0,   0,  ..., 104, 170, 422],\n","        [  0,   0,   0,  ...,   2, 187, 204]])\n","Sample input: \n"," tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n","        0, 0])\n"]}],"source":["# obtain one batch of training data\n","dataiter = iter(train_loader)\n","sample_x, sample_y = next(dataiter)\n","\n","print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n","print('Sample sentences x: \\n', sample_x)\n","print('Sample targets y: \\n', sample_y)"]},{"cell_type":"markdown","metadata":{"id":"-dlWW_ahyt3o"},"source":["## Part 4: Model structure\n","\n","We need to add an embedding layer because there are less words in our vocabulary. It is massively inefficient to one-hot encode that many classes. So, instead of one-hot encoding, we can have an embedding layer and use that layer as a lookup table. You could train an embedding layer using Word2Vec, then load it here. But, it's fine to just make a new layer, using it for only dimensionality reduction, and let the network learn the weights.\n","\n","**Common Steps for Model Initialization:**\n","1. Define Model architecture\n","2. Create model instance\n","3. Move model to device\n","4. Define loss function\n","5. Choose optimizer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYq41GQB2Cir"},"outputs":[],"source":["class SentimentRNN(nn.Module):\n","    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim):\n","        super(SentimentRNN,self).__init__()\n","\n","        self.output_dim = output_dim\n","        self.hidden_dim = hidden_dim\n","\n","        self.no_layers = no_layers\n","        self.vocab_size = vocab_size\n","\n","        # embedding and LSTM layers\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","\n","        #lstm\n","        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n","                           num_layers=no_layers, batch_first=True)\n","\n","\n","        # dropout layer\n","        self.dropout = nn.Dropout(0.3)\n","\n","        # linear and sigmoid layer\n","        self.fc = nn.Linear(self.hidden_dim, output_dim)\n","        self.sig = nn.Sigmoid()\n","\n","    def forward(self,x,hidden):\n","        batch_size = x.size(0)\n","        # embeddings and lstm_out\n","        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n","        # print(embeds.shape)  #[50, 500, 64]; 64 is the embedding_dim defined below.\n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","\n","        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n","\n","        # dropout and fully connected layer\n","        out = self.dropout(lstm_out)\n","        out = self.fc(out)\n","\n","        # sigmoid function\n","        sig_out = self.sig(out)\n","\n","        # reshape to be batch_size first\n","        sig_out = sig_out.view(batch_size, -1)\n","\n","        sig_out = sig_out[:, -1] # get last batch of labels\n","\n","        # return last sigmoid output and hidden state\n","        return sig_out, hidden\n","\n","\n","\n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n","        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n","        hidden = (h0,c0)\n","        return hidden"]},{"cell_type":"markdown","metadata":{"id":"9u1dh5YdzdhT"},"source":["Define the hyperparameters and pass to the model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1691856551180,"user":{"displayName":"Kevin Tang","userId":"05036585668706905920"},"user_tz":-480},"id":"VtZYrj2p2GAo","outputId":"ef08fda2-1348-48d9-916a-8c29d9b7ffa8"},"outputs":[{"name":"stdout","output_type":"stream","text":["SentimentRNN(\n","  (embedding): Embedding(1001, 64)\n","  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (fc): Linear(in_features=256, out_features=1, bias=True)\n","  (sig): Sigmoid()\n",")\n"]}],"source":["no_layers = 2\n","vocab_size = len(vocab) + 1 #extra 1 for padding\n","embedding_dim = 64\n","output_dim = 1\n","hidden_dim = 256\n","\n","\n","model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim)\n","\n","#moving to gpu\n","model.to(device)\n","\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"azgxjQdyziik"},"source":["We set the learning rate and optimizer. Use accuracy as the metric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4vZXCyW2JKC"},"outputs":[],"source":["lr=0.001\n","\n","criterion = nn.BCELoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","# function to predict accuracy\n","def acc(pred,label):\n","    pred = torch.round(pred.squeeze())\n","    return torch.sum(pred == label.squeeze()).item()"]},{"cell_type":"markdown","metadata":{"id":"yRszSB9g5Wl2"},"source":["## Part 5: Training and evaluation\n","\n","Here is a training loop. It iterates through each training epoch, and at the end of each epoch, it displays the training and validation losses along with the accuracy.\n","\n","**Steps Involved in Training:**\n","1. Loop Through Epochs: Set the number of training epochs and loop through them.\n","\n","2. Set Model to Train Mode: Put the model in training mode using .train(). This enables layers like dropout to work during training.\n","\n","3. Initialize Hidden States: For each epoch, initialize the hidden and cell states of the LSTM layers before processing a new sequence.\n","\n","4. Loop Through Batches: Iterate through batches of training data.\n","\n","5. Zero Gradients: Before each batch, zero out the gradients of the model's parameters using .zero_grad().\n","\n","6. Forward Pass: Pass the input sequence through the LSTM model to obtain predictions.\n","\n","7. Calculate Loss: Calculate the loss between the predictions and the actual target values using the chosen loss function.\n","\n","8. Backpropagation: Perform backpropagation to compute gradients of the loss with respect to the model's parameters.\n","\n","9. Gradient Clipping: Apply gradient clipping to prevent exploding gradients, especially in RNNs like LSTMs.\n","\n","10. Optimizer Step: Update the model's parameters using the chosen optimizer's .step() method.\n","\n","**Steps Involved in Evaluation:**\n","1. Set Model to Evaluation Mode: Put the model in evaluation mode using .eval(). This disables layers like dropout during evaluation.\n","\n","2. Initialize Hidden States: Initialize the hidden and cell states of the LSTM layers before processing each sequence.\n","\n","3. Loop Through Test Data: Iterate through batches of test data.\n","\n","4. Forward Pass: Pass the input sequence through the model to obtain predictions.\n","\n","5. Calculate Loss or Metrics: Calculate loss or any evaluation metrics appropriate for your task (accuracy, F1-score, etc.).\n","\n","6. Aggregate Metrics: Calculate and aggregate metrics across all test batches to get an overall performance measure."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":129436,"status":"ok","timestamp":1691856680603,"user":{"displayName":"Kevin Tang","userId":"05036585668706905920"},"user_tz":-480},"id":"1JkF0TBd2R9W","outputId":"ab1e3d37-90a2-4084-d48a-662874fbdde0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","train_loss : 0.6601921334862709 val_loss : 0.5948982119560242\n","train_accuracy : 59.75 val_accuracy : 68.0\n","==================================================\n","Epoch 2\n","train_loss : 0.5558413974940777 val_loss : 0.5302614092826843\n","train_accuracy : 72.7 val_accuracy : 75.1\n","==================================================\n","Epoch 3\n","train_loss : 0.4677178584039211 val_loss : 0.46618108451366425\n","train_accuracy : 78.325 val_accuracy : 77.8\n","==================================================\n","Epoch 4\n","train_loss : 0.4355272766202688 val_loss : 0.4870410054922104\n","train_accuracy : 81.3 val_accuracy : 77.4\n","==================================================\n","Epoch 5\n","train_loss : 0.3629693147726357 val_loss : 0.48650067672133446\n","train_accuracy : 85.0 val_accuracy : 77.3\n","==================================================\n","Epoch 6\n","train_loss : 0.303387201204896 val_loss : 0.5234006613492965\n","train_accuracy : 87.47500000000001 val_accuracy : 77.5\n","==================================================\n","Epoch 7\n","train_loss : 0.27275250852108 val_loss : 0.6018998607993126\n","train_accuracy : 89.0 val_accuracy : 80.2\n","==================================================\n","Epoch 8\n","train_loss : 0.2096931732259691 val_loss : 0.5993746384978295\n","train_accuracy : 91.77499999999999 val_accuracy : 80.7\n","==================================================\n","Epoch 9\n","train_loss : 0.12691445399541407 val_loss : 0.7711191713809967\n","train_accuracy : 95.125 val_accuracy : 77.8\n","==================================================\n","Epoch 10\n","train_loss : 0.08936895370716229 val_loss : 0.9611318111419678\n","train_accuracy : 96.825 val_accuracy : 78.60000000000001\n","==================================================\n","Epoch 11\n","train_loss : 0.06659541378030553 val_loss : 0.9281963914632797\n","train_accuracy : 97.925 val_accuracy : 75.7\n","==================================================\n","Epoch 12\n","train_loss : 0.04291580910794437 val_loss : 1.0775825053453445\n","train_accuracy : 98.725 val_accuracy : 77.60000000000001\n","==================================================\n","Epoch 13\n","train_loss : 0.019406577467452734 val_loss : 1.153731906414032\n","train_accuracy : 99.375 val_accuracy : 78.7\n","==================================================\n","Epoch 14\n","train_loss : 0.017752616036887048 val_loss : 1.3148091211915016\n","train_accuracy : 99.425 val_accuracy : 78.8\n","==================================================\n","Epoch 15\n","train_loss : 0.04984048399564926 val_loss : 1.0434221863746642\n","train_accuracy : 98.3 val_accuracy : 77.5\n","==================================================\n","Epoch 16\n","train_loss : 0.024235726437473203 val_loss : 1.1150915801525116\n","train_accuracy : 99.175 val_accuracy : 77.8\n","==================================================\n","Epoch 17\n","train_loss : 0.01583799177824403 val_loss : 1.2335231393575667\n","train_accuracy : 99.52499999999999 val_accuracy : 74.4\n","==================================================\n","Epoch 18\n","train_loss : 0.024739662446518196 val_loss : 1.232058823108673\n","train_accuracy : 99.075 val_accuracy : 77.7\n","==================================================\n","Epoch 19\n","train_loss : 0.00863276076506736 val_loss : 1.4014286279678345\n","train_accuracy : 99.8 val_accuracy : 77.4\n","==================================================\n","Epoch 20\n","train_loss : 0.023368830992330912 val_loss : 1.2705364927649498\n","train_accuracy : 99.3 val_accuracy : 76.2\n","==================================================\n"]}],"source":["# set the gradient clipping threshold and number of training epochs\n","clip = 5\n","epochs = 20\n","\n","# Initialize the minimum validation loss as positive infinity\n","valid_loss_min = np.Inf\n","\n","epoch_tr_loss,epoch_vl_loss = [],[]\n","epoch_tr_acc,epoch_vl_acc = [],[]\n","\n","for epoch in range(epochs):\n","    train_losses = []\n","    train_acc = 0.0\n","    # set the model to training mode\n","    model.train()\n","    # initialize hidden state\n","    h = model.init_hidden(batch_size)\n","    for inputs, labels in train_loader:\n","\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","        h = tuple([each.data for each in h])\n","\n","        # Clear the gradients\n","        model.zero_grad()\n","        # Perform a forward pass through the model\n","        output,h = model(inputs,h)\n","\n","        # calculate the loss and perform backpropogation\n","        loss = criterion(output.squeeze(), labels.float())\n","        loss.backward()\n","        train_losses.append(loss.item())\n","\n","        # calculating accuracy\n","        accuracy = acc(output,labels)\n","        train_acc += accuracy\n","        # Gradient Clipping: `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        # Optimizer Step: Update the model's parameters using the optimizer\n","        optimizer.step()\n","\n","\n","    # validation\n","    # Set Model to Evaluation Mode\n","    model.eval()\n","    # Initialize Hidden States\n","    val_h = model.init_hidden(batch_size)\n","    val_losses = []\n","    val_acc = 0.0\n","    # Loop Through Test Data\n","    for inputs, labels in valid_loader:\n","            val_h = tuple([each.data for each in val_h])\n","\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            # Forward Pass\n","            output, val_h = model(inputs, val_h)\n","\n","            # Calculate Loss and Metrics(Accuracy)\n","            val_loss = criterion(output.squeeze(), labels.float())\n","            val_losses.append(val_loss.item())\n","            accuracy = acc(output,labels)\n","            val_acc += accuracy\n","\n","    epoch_train_loss = np.mean(train_losses)\n","    epoch_val_loss = np.mean(val_losses)\n","    # Aggregate Metrics\n","    epoch_train_acc = train_acc/len(train_loader.dataset)\n","    epoch_val_acc = val_acc/len(valid_loader.dataset)\n","    epoch_tr_loss.append(epoch_train_loss)\n","    epoch_vl_loss.append(epoch_val_loss)\n","    epoch_tr_acc.append(epoch_train_acc)\n","    epoch_vl_acc.append(epoch_val_acc)\n","    print(f'Epoch {epoch+1}')\n","    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n","    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n","    print(25*'==')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"18Izr8_LW1Oev3p3LbUEATtEDoxUkgQMy","timestamp":1691994720981}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
